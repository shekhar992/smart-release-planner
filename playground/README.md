# ğŸ§ª AI Agents Playground

**âš ï¸ EXPERIMENTAL ZONE - DO NOT DEPLOY**

This folder contains experimental AI agent development work. Nothing here affects the production application.

## What's This?

We're building AI agents to convert PRD/BRD documents into tickets using **Ollama** (free, local LLMs).

## Safety & Compliance

- âœ… All AI processing happens **locally** (Ollama on your machine)
- âœ… No data sent to external services
- âœ… No changes to existing business logic
- âœ… Isolated from production code
- âœ… Test documents are gitignored

## Folder Structure

```
playground/
â”œâ”€â”€ README.md                    # You are here
â”œâ”€â”€ test-documents/              # Sample PRDs (gitignored)
â”œâ”€â”€ agents/                      # Agent implementations
â”‚   â”œâ”€â”€ base.ts                  # Base Agent class
â”‚   â”œâ”€â”€ documentParser.ts        # Extracts text from PDFs
â”‚   â”œâ”€â”€ requirementsExtractor.ts # Finds requirements
â”‚   â””â”€â”€ ticketGenerator.ts       # Creates tickets
â”œâ”€â”€ lib/
â”‚   â””â”€â”€ ollama-client.ts         # Ollama API wrapper
â”œâ”€â”€ orchestrator.ts              # Multi-agent coordinator
â”œâ”€â”€ types.ts                     # TypeScript interfaces
â””â”€â”€ ui/                          # Test UI components
    â””â”€â”€ AgentPlayground.tsx      # Isolated testing interface
```

## Getting Started

### 1. Install Ollama

```bash
# Install Ollama (one-time)
brew install ollama

# Start Ollama service
ollama serve &

# Pull a model (choose based on speed vs quality)
ollama pull llama3.2:3b     # Fast, 2GB download
# OR
ollama pull mistral:7b      # Better quality, 4GB download
# OR
ollama pull qwen2.5:14b     # Best quality, 8GB download
```

### 2. Install Dependencies

```bash
npm install ollama pdf-parse
```

### 3. Test It

```bash
# Run the playground
npm run playground
```

## Learning Resources

- [Ollama Docs](https://ollama.com/docs)
- [What Are AI Agents?](./docs/AGENTS_101.md) (to be created)
- [LangChain Concepts](https://js.langchain.com/docs/)

## Models We're Using

| Model | Size | Speed | Quality | Use Case |
|-------|------|-------|---------|----------|
| llama3.2:3b | 2GB | âš¡âš¡âš¡ | â­â­ | Quick parsing |
| mistral:7b | 4GB | âš¡âš¡ | â­â­â­ | Main agent |
| qwen2.5:14b | 8GB | âš¡ | â­â­â­â­ | Complex reasoning |

**Your M4 MacBook can handle all of these easily!**

## Current Status

- [x] Folder structure created
- [ ] Ollama installed
- [ ] First agent built
- [ ] Test UI created
- [ ] Working end-to-end demo

---

**Remember:** This is a learning sandbox. Break things, experiment, have fun! ğŸ§ª
